---
title:  | 
  Jornadas de Data Mining y Business Intelligence

subtitle: |
  Casuística de Implementación II
  \
  \
  Maestría en Explotación de Datos y Gestión del Conocimiento
author: |
  Franco Lianza, Alexis Walker
date: |
  `r format(Sys.time(), '%d %B %Y')`

header-includes:
- \usepackage{titling}
- \usepackage{floatrow}
- \usepackage{graphicx}

- \renewcommand{\figurename}{Fig.}
- \renewcommand{\contentsname}{Índice}
- \renewcommand{\tablename}{Tabla}

- \pretitle{
      \begin{center}
      \includegraphics[width=2in,height=2in]{logo.png}\LARGE\\
      \vskip 12em
      \thispagestyle{empty}
  }
- \posttitle{\end{center}}

- \preauthor{
      \begin{center}
      \vskip 26em
  }
- \postauthor{\end{center}}
  
- \predate{\begin{center}}
- \postdate{
    \end{center}
    \vskip 4em
    \cleardoublepage
  }

output: 
  bookdown::pdf_document2:
    toc_depth: 3
---

\thispagestyle{empty}
\newpage



# DataOps y MLOps: Cómo escalar el delivery de productos de datos sin morir en el intento

Con el ya instituido entendimiento en distintos estratos y roles dentro de las compañías sobre la necesidad de trabajar con datos, y su carácter de activo que conlleva a reconocer el valor estratégico de su explotación; es importante ocuparse del ciclo de vida de los mismos. Este concepto se identifica en la industria como: *DataOps* y *MLOps*.

Muchos intentos de incorporar esta capacidad dentro del departamento de IT terminan en proyectos inconclusos debido a la falta de gestión de la deuda técnica y metodológica vinculada al gobierno y ciclo de vida del entregable de un científico de datos.

Se recorre un poco de historia para comprender el estado del arte actual que permite sortear el inconveniente antes planteado:

2008 - Se introduce el concepto de *DevOps* que pretende agilizar el proceso de desarrollo de software focalizando en la entrega continua (construcción, implementación y mantenimiento).

2014 - Se empieza a discutir sobre *DataOps*, el universo ya no solo se centra en el código sino que se suman los datos.

2015 - Google, en su paper _Hidden Technical Debt in Machine Learning Systems_, visibiliza la carencia metodológica y la deuda técnica que existía en los equipos de ciencias de datos. Lo que introduce la idea de *MLOps*, donde ahora son tres los elementos: código, datos y modelos; y su gestión para escalar la entrega de este tipo de productos.

## Racionales

Hoy, las soluciones originadas a partir de los datos se tornaron críticas; esto debido a estar cada vez más embebidas en los sistemas *cores* de una empresa. Por otro lado, la evidencia concreta del valor que son capaces de otorgar, ha significado una importante alfabetización de las áreas usuarias, implicando una mayor y más compleja demanda. Esto se traduce en la exposición de aquellos profesionales encargados de desarrollarlas.

Los problemas comunes que surgen en este contexto suelen ser: el flujo regular de nuevas necesidades producto de los casos de éxito, la baja calidad de los datos y la constante posibilidad de evolucionar el entregable (siempre existe algo para mejorar).

Estos inconvenientes se suelen abordar, erróneamente, sobreexigiendo al equipo de desarrollo (lo que no escala debido a la aparición continua de requerimientos), siendo optimistas en el resultado obtenido, o bien, sobrestimando la capacidad necesaria para amortiguar cualquier desfajase de calendario.

Al panorama descrito se suma una baja credibilidad en las chances de éxito que este tipo de proyecto tiene, sustentada por estudios realizados por las principales consultoras globales.

La realidad detallada, es el *driver*, la argumentación que tracciona la necesidad de implementar nuevas herramientas para aumentar y mejorar el procesamiento. Concretamente el primer concepto que delimita este camino es *DataOps*, y posteriormente *MLOps*.

Para acortar los ciclos de desarrollo manteniendo la calidad, se combina: **Agile + DevOps + SPC = DataOps**. Donde, el agilismo incorpora al usuario, debido a la naturaleza cambiante del entorno, para poder hacer entregas rápidas que agreguen valor. Dentro de estas pretensiones, la infraestructura es provista como servicio, evitando así, demoras en su configuración. Y, por último, se automatiza el control estadístico de procesos (SPC), es decir, en las distintas etapas de enriquecimiento de los datos se realizan validaciones para garantizar la calidad del resultado final.

## Conceptos heredados de la industria del software

El cambio conceptual planteado y argumentado hasta el momento esta muy bien instanciado en algunas herramientas tecnológicas que permiten materializar las ideas subyacentes.

### DataOps

El concepto cumbre e inicial de esta evolución es el **versionado de código** debido a que el equipo de datos trabajan sobre un código base. E inmediatamente se vincula a éste su **ciclo de vida** (figura \@ref(fig:devops)).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{mlops/devops.png}
    \caption{Integración/Entrega/Despliegue Continuo}
    \label{fig:devops}
\end{figure}

Integración continua: los desarrollos que pueden hacer distintos miembros del equipo deben ser validados antes de integrarse al código fuente base.

Entrega continua: se agrega valor en cada iteración.

Despliegue continuo: implementación con baja fricción.

Por último, las pruebas no solo verifican la calidad del código, sino también, en este esquema, la de los datos, incorporando entonces el **control estadístico de procesos**.

### MLOps

Cuando se suma la convivencia con los modelos al *workflow* de trabajo donde se presentan los conceptos enumerado anteriormente (garantizando la calidad de los datos), hablamos de *MLOps*.

Esta evolución responde a una problemática real originada por: la necesidad de monitoreo, el etiquetado de los datos, la comprensión del resultado (modelos), la optimización de inferencia, los dispositivos *edge* (por ejemplo: celulares) y la privacidad de datos sensibles.

## Ejemplo

**MLflow** es una tecnología *open source* que convive facilmente con otras y ayuda a resolver las principales etapas enumeradas en el flujo de trabajo (figura \@ref(fig:mlflow)).

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{mlops/mlflow.jpg}
    \caption{mlflow}
    \label{fig:mlflow}
\end{figure}

Concretamente permite administrar el ciclo de vida de productos de *Machine Learning (ML)*, incluida la experimentación, la reproducibilidad, la implementación y un registro de modelos central.

Es posible el monitoreo de datos (controlando también su dominio), de los valores tomados por los parámetros, de las métricas de resultados y, además, el control del entorno donde se entrenó el modelo y la serialización del mismo.

Con esto bajo gobierno, es sencillo promover un experimento como resultado definitivo en el registro.

## Conclusiones

Lo expresado no se trata de implementar un software que ayude al equipo de ciencia de datos a desarrollar mejor, no se describe un problema tecnológico. Por el contrario, se propone un cambio en su dinámica de trabajo para ayornarlos a la criticidad que ha cobrado hoy en día el producto que construyen. 

Es por todo esto que el proceso de ejecutar *ML* debe ser tan sencillo como el trabajo de ejecutar sistemas de IT.

\newpage

# ¿Qué hotel va primero para vos? Un ejemplo del desafio de usar Machine Learning para ordenar hoteles en Despegar.com

_Despegar.com_ se encontraba ante la incógnita de si era posible ordenar los hoteles que se mostraban a los usuarios basado en la probabilidad de compra en tiempo real de manera de optimizar la conversión. La idea era generar un sistema que ante una búsqueda del usuario clasifique y ordene los resultados obteniendo algún tipo de score que pueda ser interpretado como probabilidad de compra.

## El problema del Sorting

El sorting es un tipo de problema que consiste en la aplicación de algoritmos de *Machine Learning* cuyo objetivo es optimizar la ubicación de los items de los más relevantes a los menos relevantes. Para esto, existen 3 enfoques distintos: 

- **_Pointwise_**: el modelo se aplica sobre cada ítem de manera individual, es decir se utilizan las características propias del ítem sin mirar a las del resto. El ordenamiento se da por el score individual de cada ítem.
- **_Pairwise_**: el modelo se aplica sobre cada par de ítem, de forma que se comparan las características de cada uno a fin de obtener el mejor de ambos. El ordenamiento final es relativo a los scores de cada par.
- **_Listwise_**: el modelo se aplica sobre la lista entera de items y busca optimizar alguna métrica de ordenamiento como Ganancia _Acumulada Descontada Normalizada (NDCG)_ o la _Precisión Media Promedio (MAP)_.

Solo el ordenamiento _pointwise_ provee scores que pueden ser interpretables como probabilidades, por lo que el proyecto utilizó este enfoque por sobre los otros.

Otro de los problemas encontrados durante la investigación sobre el sorting es el _sesgo de la posición_. En los análisis exploratorios realizados se encontró que la probabilidad de saber si un ítem es relevante para un usuario-contexto disminuye con la posición. Este sesgo complica el trabajo de entender cuánto influye las características del hotel y cuanto influye la posición en la que se muestra.

## Diseño

El diseño del producto fue separado en 4 etapas: estimación del sesgo de la posición de los datos actuales, entrenamiento del modelo (feature engineering y modelado), post procesamiento de scores y evaluación offline.

### Estimacion del sesgo

La posición de un ítem influye en la probabilidad de compra, es decir, es más probable comprar items que aparezcan en los primeros resultados. Este sesgo debe ser medido de alguna forma para poder incorporarlo al modelo. El equipo de _Despegar.com_ utilizaron el _algoritmo Expectation-Maximization_ obteniendo un **ponderador** para utilizar en el modelo. Este ponderador puede ser interpretado como _la probabilidad de que el usuario haya visto el ítem_.

### Entrenamiento del modelo

Los datos que se utilizaron para el armado del dataset consistían en características propias del contexto, del hotel, del contexto y hotel y finalmente, el target binario de si la persona compraba el hotel o no. La figura \@ref(fig:despegar-features) muestra algunos ejemplos utilizados.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{despegar/features.png}
    \caption{Features utilizados}
    \label{fig:despegar-features}
\end{figure}

Algunas de estas *features* pueden ser obtenidas en tiempo real y otras tuvieron que pre-computarlas y dejarlas en un _feature store_ para que se pudiesen consumir de manera online.

Para el modelado, se utilizo un _XGBoost por cada destino_ por varias razones: por su potencia predictiva y por su portabilidad. El sistema transaccional de Despegar.com se encuentra programado en Scala, por lo que la elección de XGBoost les permitió programarlos en Python y luego ponerlos productivos en Scala.

La evaluación del modelado consistió en dos momentos: offline y online. La evaluación offline fue medida con métricas de clasificación (F-score) y métricas de probabilidad (Negative Log Loss). La online, mediante 3 KPIs definidos por el negocio: _tasa de conversión_, _margen por usuario_ e _ingreso_. A su vez, el modelo fue deployado utilizando un esquema A/B para algunos de los destinos seleccionados.

### Post procesamiento de scores

Luego del entrenamiento, los scores obtenidos fueron post procesados en función del enfoque.

En el _enfoque de clasificación_, se definió un umbral por el cual los hoteles eran clasificados en "relevantes" y "no relevantes". De esta manera se optimizaba de manera eficiente el F-score.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{despegar/enfoque_clasificacion.png}
    \caption{Enfoque de Clasificacion}
    \label{fig:despegar-enfoque-clasificacion}
\end{figure}

En el _enfoque de probabilidades_, se optimiza la métrica negative log loss (NLL) para medir diferencias entre el score ($z$) y el target de compra o no compra ($y$).

\begin{equation}
  NLL = \sum_{i=-1}^{N} y_i + \log z_i + (1 - y_i) \log (1 - z_i)
  (\#eq:despegar-nll)
\end{equation}

A su vez, se utilizaron _gráficos de calibración_. Éstos permiten observar la relación de los scores medidos y la tasa de conversión. La idea general de esta herramienta es agrupar hoteles de manera similar y graficar las medidas. Resultó de gran importancia durante el desarrollo ya que se puede compartir con otras áreas de Despegar.com debido a que son simples de interpretar: siempre y cuando se muestre una tendencia positiva, el modelo funciona correctamente.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.5\textwidth]{despegar/grafico_calibracion.png}
    \caption{Grafico de Calibración.}
    \label{fig:despegar-grafico-calibracion}
\end{figure}

### Evaluación

El equipo decidió realizar una POC con el enfoque de _clasificación_ obteniendo resultados mixtos en los KPIs. En la siguiente iteración, se cambió al enfoque de _probabilidades_.

El enfoque de _probabilidades_ resultó ser el mejor. La Figura \@ref(fig:despegar-grafico-calibracion-resultados) muestra los gráficos de calibración obtenidos por enfoque.

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{despegar/grafico_calibracion_resultados.png}
    \caption{Graficos de calibración obtenidos por enfoque.}
    \label{fig:despegar-grafico-calibracion-resultados}
\end{figure}

En la Figura \@ref(fig:despegar-resultados) se detalla el comportamiento de cada KPI en función de su enfoque.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{despegar/resultados.png}
    \caption{Resultados obtenidos por enfoque.}
    \label{fig:despegar-resultados}
\end{figure}

## Conclusiones

Es interesante mencionar que la ciencia de datos puede estar en cualquier lado, incluso en ordenamiento de listas. Durante toda la charla, los miembros de Despegar.com mencionaron la importancia de analizar el estado del arte y de hacer pruebas de concepto (POCs) para poder involucrar al negocio lo mas temprano posible.

Otro punto interesante a recalcar es que, si bien la métrica más lógica a optimizar es el F-score (al tratarse de un problema de clasificación), no siempre es la que optimiza mejor los KPIs. No hay que perder el foco de las métricas de negocio a optimizar. Las métricas "clásicas" deben ser de soporte, pero las métricas de negocio son las que nos tienen que definir los modelos o enfoques a seguir.



